# Created Sam Cubberly
# all information that'll show in the teaching tab of the program

classes:
  - name: "Artificial Intelligence I: Basic Techniques"
    number: CSE 3521
    taught: Spring 2009
  - name: "Survey of Artificial Intelligence II: Advanced Techniques"
    number: CSE 5522
    taught: Autumn 2019
  - name: "Foundations of Speech and Language Processing"
    number: CSE 5525
    taught: Spring 2021
  - name: "Introduction to Neural Networks"
    number: CSE 5526
    taught: Spring 2022
  - name: "Intermediate Studies in Artificial Intelligence (Seminar)"
    number: CSE 5539
    taught: Spring 2023
  - name: "Capstone Design: Knowledge-Based Systems"
    number: CSE 5914
    taught: Spring 2016
  - name: "Artificial Intelligence"
    number: CSE 6521
    taught: Autumn 2020
resources:
  - name: Convolution demo
    type: Google Colab/Jyupter Notebook
    number: CSE 5526
    description:
    image: "images/teachingIcons/convolutiondemo.png"
    link: https://colab.research.google.com/drive/1SdsSNj_AmyajG5QTknOeQCiEdSMI6zZq?usp=sharing
  - name: Build an SVM demo
    type: Google Colab/Jyupter Notebook
    number: CSE 5526
    description:
    image: "images/teachingIcons/svmdemo.png"
    link: https://colab.research.google.com/drive/12IpcPrubBlxkx5wPyRd9O1e-d59nyQs8?usp=sharing
  - name: Pytorch Intro for Neural Networks
    type: Google Colab/Jyupter Notebook
    number: CSE 5526
    description:
    image: "images/teachingIcons/pytorchintro.png"
    link: https://colab.research.google.com/drive/1Z-fJwfiABcsbMuv-mX51wR_6D1QFKaYu?usp=sharing
  - name: K-Means demo
    type: Google Colab/Jyupter Notebook
    number: CSE 5526
    description:
    image: "images/teachingIcons/kmeansdemo.png"
    link: https://colab.research.google.com/drive/1gOWOnMuatux-Q_v3WD1tFCK_L5t9Riax?usp=sharing
  - name: Function fitting
    type: Google Colab/Jyupter Notebook
    number: CSE 5526
    description:
    image: "images/teachingIcons/functionfitting.png"
    link: https://colab.research.google.com/drive/1lEPTXSHrdxjtBSEaT1GozCrnxzpuG5NE?usp=sharing
  - name: Get to know you clustering
    type: GoogleColab/Jyupter Notebook
    number: CSE 5522/6521
    description: "A method for forming groups by clustering answers based on a survey. Mostly used to begin a discussion of fairness and bias (and bad algorithms) in AI."
    image:
    link: https://colab.research.google.com/drive/1nTGLKxr7Q53OmGyno2NJTAFoawKnC9Cz?usp=sharing
  - name: Naive Bayes Sentiment Analysis
    type: GoogleColab/Jyupter Notebook
    number: CSE 5522/6521
    description: Credit to Amir Asiaee for CSE 5522.
    image: "images/teachingIcons/naivebayes.png"
    link: https://colab.research.google.com/drive/1YL034mgUUVp5-hErl32Ac2CExhRvpxX8?usp=sharing
  - name: Percepton Learning Rule
    type: MP4 Video
    number: CSE 5522/5526
    description: "This demo shows the PLR learning a 2-dimensional hyperplane between two separable classes. The thing to note is that at convergence, the red line (hypothesis) does not match the true function (blue dashed line) -- the end hypothesis will depend on the training data."
    image: "images/teachingIcons/perceptron.png"
    link: https://efosler.github.io/movies/plr.mp4
  - name: K-means demo
    type: MP4 Video
    number: CSE 5522
    description: 'This older demo shows k-means clustering of 4 and 8 data clusters in 2 dimensions. I use this demo as a jumping off point to show that random initialization can lead to "incorrect" clusters. The first demo has 4 relatively separate data clusters, and k-means comes up with a pretty good clustering. The iterations first show a mean assignment, and then the data points are colored according to the closest mean. The iteration continues until convergence. The second movie shows the example with 8 means and a "bad" initialization. After 11 shots at initialization, I did get one that worked (demo 3). Someone in the class ususally picks up on the fact that the number of "clusters" and number of means are matched in the video, which can be used to generate a discussion of different techniques for finding the number of means.'
    image: "images/teachingIcons/kmeansdemo2.png"
    link: https://efosler.github.io/movies/kmeans.mp4
  - name: 1-dimensional Gaussian EM demo
    type: MP4 Video
    number: CSE 5522
    description: "This demo shows learning of a 3-mixture of Gaussians over one dimensional data. I particularly like this demo because it shows how the means and variances evolve over EM iterations. The means are represented by the center of the line in each graph; the variance is represented by the width of the line. The data were generated by three overlapping Gaussians, and in this case the EM algorithm does recover the means and variances of the original generating functions pretty accurately."
    image: "images/teachingIcons/gaussian.png"
    link: https://efosler.github.io/movies/1dgauss.mp4
  - name: 2-dimensional Gaussian EM demo
    type: MP4 Video
    number: CSE 5522
    description: "This is similar to the 1-d demo, but uses data that are 2-dimensional. I used diagonal covariance matrices here (I was too lazy to code up the full covariance version :-), but this also gives me the ability to talk about what happens if you use diagonal covariance matrices (notice the axis-parallel ellipsoids). This is a case where the EM algorithm does not converge to the same parameters that generated the data (pretty obvious in the movie). The particular algorithm I used here was to start by taking the global mean of the data, then splitting the Gaussian cloning the mean and perturbing it slightly and letting EM converge. I then iteratively split the each Gaussian, perturb, and let EM converge again. This is similar to some techniques used in speech recognition Gaussian modeling but is not the only way to do this."
    image: "images/teachingIcons/gaussian2d.png"
    link: https://efosler.github.io/movies/2dgauss.mp4

